{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6aGvVOPrrfm",
        "outputId": "2f6c4f3b-37e8-4fbc-dcc9-525a098c6ad8"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e2z8jggUJyA"
      },
      "source": [
        "## ***<span style=\"color: orange;\">Construire un Nano-LLM pour le Résumé de Texte</span>***\n",
        "\n",
        "---\n",
        "\n",
        "**Ce noteook contient les principales étapes pour entrainer un LLM(`GPT-2`) pour le résumé de text**\n",
        "1. <span style=\"color: cyan;\">Nettoyage de données :</span> Simplifier le texte pour faciliter l'apprentissage\n",
        "2. <span style=\"color: cyan;\">Pré-entraînement :</span> Apprendre au modèle la structure de la langue anglaise sur un corpus brut\n",
        "3. <span style=\"color: cyan;\">Fine-tuning :</span> Spécialiser le modèle pour qu'il sache résumer du texte\n",
        "4. <span style=\"color: cyan;\">Évaluation & Inférence :</span> Tester les performances avec la métrique ***<span style=\"color: red;\">ROUGE</span>***\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrvB89r6reQ0"
      },
      "source": [
        "#### <u><span style=\"color:#1E90FF\">***1. Installation et Importation des Outils***</span></u>\n",
        "\n",
        "Les importations nécessaires sont énumérées ci-dessous:\n",
        "- `pytorch`: Pour construire et entraîner le réseau de neurones\n",
        "- `SpaCy`: Pour le traitemnt linguistique(nettoyage, lemmatisation...)\n",
        "- `torchMetrics`: Pour calculer le score <span style=\"color: red;\">ROUGE</span>(évaluation standard en résumé automatique)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYMiIX5dTT3G"
      },
      "outputs": [],
      "source": [
        "# !pip install nltk spacy torch numpy pandas tqdm torchmetrics pip  nltk\n",
        "# !python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUy25bTmUZuq",
        "outputId": "a7504e81-8e06-47a2-d3c1-1a0f7855e8ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from torchmetrics.text import ROUGEScore\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SHg1pRwUxln"
      },
      "source": [
        "#### <u><span style=\"color:#1E90FF\">***2. Installation et Importation des Outils***</span></u>\n",
        "\n",
        "Pour cette tâche, deux fichiers de données sont nécessaires pour la phase d'entraînement.\n",
        "\n",
        "1. <span style=\"color:#32CD32;\"><strong>Corpus Brut</strong></span> : Une grande quantité de données textuelles non traité venant du web pour apprendre la structure générale de la langue (grammaire, syntaxe).\n",
        "\n",
        "2. <span style=\"color:#32CD32;\"><strong>Dataset de Résumé</strong></span> : Des paires `Texte -> Résumé` pour apprendre la tâche spécifique.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HIY5meRU1Cv"
      },
      "outputs": [],
      "source": [
        "# importation du corpus\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/LLM_atelier/data/raw_corpus.txt\", \"r\") as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "# importation du df de résumées de textes\n",
        "df_summary = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/LLM_atelier/data/summaries.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ON8cHU6Ct_mm"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "diviser l'ensemble de données de résumés de textes\n",
        "en un ensemble d'apprentissage et un ensemble de test\n",
        "\"\"\"\n",
        "df_train = df_summary.iloc[:-5]\n",
        "df_test = df_summary.iloc[-5:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgmh5B3cU8uu"
      },
      "source": [
        "#### <u><span style=\"color:#1E90FF\">***3. Nettoyage du données***</span></u>\n",
        "\n",
        "- <span style=\"color:#32CD32\"><strong>Nettoyage</strong></span> : On retire le HTML et les URLs qui n'apportent pas de sens linguistique\n",
        "\n",
        "- <span style=\"color:#32CD32\"><strong>Lemmatisation</strong></span> : On utilise SpaCy pour transformer les mots en leur racine(**Lemmes**) (example `chattons -> chat`). Cela réduit la taille du vocabulaire nécessaire, rendant l'entraînement plus rapide sur des ressources machine limités\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKnvwqcoU9nU",
        "outputId": "03282105-f975-466b-f0ca-e81e490ee656"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['welcome', 'this', 'be', 'an', 'example', '....', 'text', 'with', 'too', 'many', 'space', '.', 'here', 'a', 'sample', 'cat', 'be', 'amazing', 'animal', 'this', 'be', 'another', 'sentence', 'but', 'its', 'repeat', '.', 'this', 'be', 'another', 'sentence', 'but', 'its', 'repeat', '.', 'random', 'tweet', 'lol', 'soooo', 'cool', 'bonjour', 'le', 'monde', 'some', 'html', 'check', 'this', 'out', 'I', 'loooove', 'nlp', 'nlp', 'nlp', 'welcome', 'this', 'be', 'an', 'example', '....', 'text', 'with', 'too', 'many', 'space', '.', 'here', 'a', 'sample', 'cat', 'be', 'amazing', 'animal', 'this', 'be', 'another', 'sentence', 'but', 'its', 'repeat', '.', 'this', 'be', 'another', 'sentence', 'but', 'its', 'repeat', '.', 'random', 'tweet', 'lol', 'soooo', 'cool', 'bonjour', 'le', 'monde', 'some', 'html', 'check', 'this', 'out', 'I', 'loooove', 'nlp', 'nlp', 'nlp', 'welcome', 'this', 'be', 'an', 'example', '....', 'text', 'with', 'too', 'many', 'space', '.', 'here', 'a', 'sample', 'cat', 'be', 'amazing', 'animal', 'this', 'be', 'another', 'sentence', 'but', 'its', 'repeat', '.', 'this', 'be', 'another', 'sentence', 'but', 'its', 'repeat', '.', 'random', 'tweet', 'lol', 'soooo', 'cool', 'bonjour', 'le', 'monde', 'some', 'html', 'check', 'this', 'out', 'I', 'loooove', 'nlp', 'nlp', 'nlp', 'welcome', 'this', 'be', 'an', 'example', '....', 'text', 'with', 'too', 'many', 'space', '.', 'here', 'a', 'sample', 'cat', 'be', 'amazing', 'animal', 'this', 'be', 'another', 'sentence', 'but', 'its', 'repeat', '.', 'this', 'be', 'another', 'sentence', 'but', 'its', 'repeat', '.', 'random', 'tweet', 'lol', 'soooo', 'cool', 'bonjour', 'le', 'monde', 'some', 'html', 'check', 'this', 'out', 'I', 'loooove', 'nlp', 'nlp', 'nlp', 'welcome', 'this', 'be', 'an', 'example', '....', 'text', 'with', 'too', 'many', 'space', '.', 'here', 'a', 'sample', 'cat', 'be', 'amazing', 'animal', 'this', 'be', 'another', 'sentence', 'but', 'its', 'repeat', '.', 'this', 'be', 'another', 'sentence', 'but', 'its', 'repeat', '.', 'random', 'tweet', 'lol', 'soooo', 'cool', 'bonjour', 'le', 'monde', 'some', 'html', 'check', 'this', 'out', 'I', 'loooove', 'nlp', 'nlp', 'nlp', 'welcome', 'this', 'be', 'an', 'example', '....', 'text', 'with', 'too', 'many', 'space', '.', 'here', 'a', 'sample', 'cat', 'be', 'amazing', 'animal', 'this', 'be', 'another', 'sentence', 'but', 'its', 'repeat', '.', 'this', 'be', 'another', 'sentence', 'but', 'its', 'repeat', '.', 'random', 'tweet', 'lol', 'soooo', 'cool', 'bonjour', 'le', 'monde', 'some', 'html', 'check', 'this', 'out', 'I', 'loooove', 'nlp', 'nlp', 'nlp']\n"
          ]
        }
      ],
      "source": [
        "# chargement du modèle NLP du spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "    pipeline de nettoyage :\n",
        "    1. suppression HTML & URLs\n",
        "    2. minuscules & suppression caractères spéciaux (sauf points)\n",
        "    3. lemmatisation (run -> running) via SpaCy\n",
        "    \"\"\"\n",
        "    text = re.sub(r'<[^>]+>', ' ', str(text)) # retire les aHTML\n",
        "    text = re.sub(r'http\\S+', ' ', text)      # retire URLs\n",
        "    text = re.sub(r\"[^a-zA-Z0-9\\s\\.]\", \"\", text.lower()) # normalizer les alphanumériques\n",
        "\n",
        "    doc = nlp(text)\n",
        "    return [token.lemma_ for token in doc if not token.is_space]\n",
        "\n",
        "# récupérez des tokens a partir de corpus.\n",
        "tokens_raw = clean_text(raw_text)\n",
        "\n",
        "print(tokens_raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_LW6k5Qt_mn"
      },
      "source": [
        "#### <u><span style=\"color:#1E90FF\">***4. Construction du Vocabulaire Unifié***</span></u>\n",
        "\n",
        "le vocabulaire unifié contient des données provenant de la collection de données qui forme le corpus (`raw_text`) et le dataset de résumé de texte(`df_summary`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r22au1p6t_mn",
        "outputId": "e52af190-a9ed-47c2-9c88-3a8b91470258"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "taille du vocab globale : 89\n"
          ]
        }
      ],
      "source": [
        "tokens_csv = []\n",
        "\n",
        "for _, row in df_train.iterrows():\n",
        "    tokens_csv.extend(clean_text(row['text']))\n",
        "    tokens_csv.extend(clean_text(row['summary']))\n",
        "\n",
        "all_tokens = tokens_raw + tokens_csv\n",
        "vocab_counts = Counter(all_tokens)\n",
        "vocab_size = 1500 # Limit size\n",
        "\n",
        "# Ajout des Tokens Spéciaux :\n",
        "# <UNK>: Mot inconnu\n",
        "# <SEP>: Séparateur (Indique au modèle : \"Le texte est fini, commence le résumé\")\n",
        "# <EOS>: Fin de séquence (Indique : \"J'ai fini de parler\")\n",
        "itos = [\"<PAD>\", \"<UNK>\", \"<SEP>\", \"<EOS>\"] + [w for w, _ in vocab_counts.most_common(vocab_size - 4)]\n",
        "stoi = {w: i for i, w in enumerate(itos)}\n",
        "\n",
        "def encode(token_list):\n",
        "    return [stoi.get(t, stoi[\"<UNK>\"]) for t in token_list]\n",
        "\n",
        "def decode(ids):\n",
        "    return \" \".join([itos[i] for i in ids])\n",
        "\n",
        "print(f\"taille du vocab globale : {len(itos)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOyruFlEreQ5"
      },
      "source": [
        "#### <u><span style=\"color:#1E90FF\">***5. Création des Tensors d'Entraînement***</span></u>\n",
        "\n",
        "Nous transformons nos textes en suites de nombres (tenseurs) que PyTorch peut comprendre.\n",
        "\n",
        "- <span style=\"color:#32CD32\">**Tenseur Pré-entraînement** :</span> Une longue suite ininterrompue de mots issus du web.\n",
        "\n",
        "- <span style=\"color:#32CD32\">**Tenseur Fine-tuning** :</span> Une suite structurée sous la forme : Article `<SEP>` Résumé `<EOS>`. C'est ainsi que nous enseignerons la tâche de résumé.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J37LkRI7t_mn",
        "outputId": "353e1aca-4353-47bd-deb0-61ac2aa68b8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "forme du tensor de pré-entraînement : torch.Size([318])\n",
            "forme du tensor de fine tune : torch.Size([651])\n"
          ]
        }
      ],
      "source": [
        "# tensor A : pré entraînement\n",
        "raw_ids = encode(tokens_raw)\n",
        "tensor_pretrain = torch.tensor(raw_ids, dtype=torch.long).to(device)\n",
        "\n",
        "# tensor B : fine tune\n",
        "# format : texte <SEP> résumé <EOS>\n",
        "ft_ids = []\n",
        "for _, row in df_train.iterrows():\n",
        "    ft_ids.extend(encode(clean_text(row['text'])))\n",
        "    ft_ids.append(stoi[\"<SEP>\"])\n",
        "    ft_ids.extend(encode(clean_text(row['summary'])))\n",
        "    ft_ids.append(stoi[\"<EOS>\"])\n",
        "\n",
        "tensor_finetune = torch.tensor(ft_ids, dtype=torch.long).to(device)\n",
        "\n",
        "print(f\"forme du tensor de pré-entraînement : {tensor_pretrain.shape}\")\n",
        "print(f\"forme du tensor de fine tune : {tensor_finetune.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIUMMchYt_mn"
      },
      "source": [
        "#### <u><span style=\"color:#1E90FF\">***6. Architecture du Modèle***</span></u>\n",
        "\n",
        "- <span style=\"color:#32CD32\"><strong>Embeddings</strong></span> : Convertit les entiers (mots) en vecteurs riches en sens.\n",
        "\n",
        "- <span style=\"color:#32CD32\"><strong>Positional Embedding</strong></span> : Ajoute la notion d'ordre (le modèle lit tout en même temps, il a besoin de savoir que le mot A est avant le mot B).\n",
        "\n",
        "- <span style=\"color:#32CD32\"><strong>Self-Attention (Masquée)</strong></span> : Permet au modèle de comprendre le contexte (\"bank\" = rivière ou argent ?). Le masquage est crucial : il empêche le modèle de \"tricher\" en regardant les mots futurs qu'il doit prédire.\n",
        "\n",
        "- <span style=\"color:#32CD32\"><strong>FeedForward</strong></span> : La couche de réflexion qui traite l'information extraite par l'attention.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "U5N0s5B1t_mo"
      },
      "outputs": [],
      "source": [
        "class Head(nn.Module):\n",
        "    def __init__(self, head_size, n_embd, block_size):\n",
        "        super().__init__()\n",
        "        # projections linéaires pour key, query & value\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "\n",
        "        #  un masque (tril) : empêche le modele d'accédé les tokens du futur\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        # k = ce que j’ai (keys)\n",
        "        k = self.key(x)\n",
        "\n",
        "        # q = ce que je cherche (query)\n",
        "        q = self.query(x)\n",
        "\n",
        "        # calcul de l’attention + scaling\n",
        "        wei = q @ k.transpose(-2, -1) * C**-0.5\n",
        "\n",
        "        #  masque pour cacher le futur\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
        "\n",
        "        # normalisation softmax = poids d’attention\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "\n",
        "        # v = values\n",
        "        v = self.value(x)\n",
        "\n",
        "        # return somme pondérée des valeurs\n",
        "        return wei @ v\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, num_heads, head_size, n_embd, block_size):\n",
        "        super().__init__()\n",
        "\n",
        "        # plusieurs HEADs mises en parallèle\n",
        "        self.heads = nn.ModuleList([\n",
        "            Head(head_size, n_embd, block_size) for _ in range(num_heads)\n",
        "        ])\n",
        "\n",
        "        # projection finale pour réassembler les HEADs\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #concaténation des sorties des têtes d’attention\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        return self.proj(out)\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "\n",
        "        # MLP appliqué après l'attention : expande → ReLU → réduit\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class NanoLLM(nn.Module):\n",
        "    def __init__(self, vocab_size, n_embd, block_size, n_head, n_layer):\n",
        "        super().__init__()\n",
        "\n",
        "        # token embedding + positionnal embedding\n",
        "        self.token_embedding = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding = nn.Embedding(block_size, n_embd)\n",
        "\n",
        "        # empilement de couches Transformer\n",
        "        self.blocks = nn.Sequential(*[\n",
        "            nn.ModuleDict(dict(\n",
        "                sa = MultiHeadAttention(n_head, n_embd // n_head, n_embd, block_size),\n",
        "                ffwd = FeedForward(n_embd),\n",
        "                ln1 = nn.LayerNorm(n_embd),\n",
        "                ln2 = nn.LayerNorm(n_embd)\n",
        "            ))\n",
        "            for _ in range(n_layer)\n",
        "        ])\n",
        "\n",
        "        # tete finale : distribution sur le vocabulaire\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # positionnal embedding\n",
        "        pos = torch.arange(T, device=idx.device)\n",
        "        x = self.token_embedding(idx) + self.position_embedding(pos)\n",
        "\n",
        "        # passage dans les blocs Transformer\n",
        "        for block in self.blocks:\n",
        "            x = x + block.sa(block.ln1(x))   # attention + skip connection\n",
        "            x = x + block.ffwd(block.ln2(x)) # feedforward + skip\n",
        "\n",
        "        # logits du modèle\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        # calcul de la loss\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKe4-zcgt_mo"
      },
      "source": [
        "#### <u><span style=\"color:#1E90FF\">***7. Entraînement Phase 1 (Pre-training)***</span></u>\n",
        "\n",
        "***<span style=\"color:#32CD32\">Objectif :*** </span> Assimiler les régularités linguistiques — par exemple, une occurrence de \"le\" est souvent suivie d’un nom. L’exposition au corpus brut permet au modèle d’ancrer ces structures fondamentales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjTToa3At_mo",
        "outputId": "0b20f0b3-a02c-4c81-b3b1-8faebc66e776"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Pre-entraienemtn avec le corpus(vocabulaire)\n",
            "Epoch N°0: Loss 4.9266\n",
            "Epoch N°100: Loss 0.0338\n",
            "Epoch N°200: Loss 0.0222\n",
            "Epoch N°300: Loss 0.0120\n",
            "Epoch N°400: Loss 0.0142\n"
          ]
        }
      ],
      "source": [
        "# les hyperparameters\n",
        "block_size = 32\n",
        "batch_size = 32\n",
        "n_embd = 64\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "lr = 1e-3\n",
        "\n",
        "def get_batch(data_source):\n",
        "    ix = torch.randint(len(data_source) - block_size, (batch_size,))\n",
        "    x = torch.stack([data_source[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data_source[i+1:i+block_size+1] for i in ix])\n",
        "    return x.to(device), y.to(device)\n",
        "\n",
        "model = NanoLLM(len(itos), n_embd, block_size, n_head, n_layer).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "loss_history = []\n",
        "\n",
        "print(\"\\n Pre-entraienemtn avec le corpus(vocabulaire)\")\n",
        "for i in range(500):\n",
        "    xb, yb = get_batch(tensor_pretrain)\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(f\"Epoch N°{i}: Loss {loss.item():.4f}\")\n",
        "        loss_history.append(loss.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1ZXozBnreQ6"
      },
      "source": [
        "#### <u><span style=\"color:#1E90FF\">***8. Entraînement Phase 2 (Fine-tuning)***</span></u>\n",
        "\n",
        "- ***<span style=\"color:#32CD32\">Objectif :***</span> Approfondir le comportement de résumé en réutilisant le même modèle, cette fois exposé à des données structurées. Le token `<SEP>` agit alors comme déclencheur signalant le début de la condensation textuelle.\n",
        "\n",
        "- ***<span style=\"color:#32CD32\">Astuce :***</span> Un abaissement du learning rate permet de préserver les schémas linguistiques acquis lors de la phase précédente et d’éviter une altération brutale des représentations internes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "CJdjStJst_mo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Fine-tune avec (tâche de résumé de texte)\n",
            "Step 0: Loss 11.3635\n",
            "Step 100: Loss 0.1463\n",
            "Step 200: Loss 0.0525\n",
            "Step 300: Loss 0.0316\n",
            "Step 400: Loss 0.0302\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# réduire le taux d'apprentissage pour le fine-tune\n",
        "for param_group in optimizer.param_groups:\n",
        "    param_group['lr'] = 5e-4\n",
        "\n",
        "print(\"\\n Fine-tune avec (tâche de résumé de texte)\")\n",
        "for i in range(500):\n",
        "    xb, yb = get_batch(tensor_finetune)\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        print(f\"Step {i}: Loss {loss.item():.4f}\")\n",
        "        loss_history.append(loss.item())\n",
        "\n",
        "plt.plot(loss_history)\n",
        "plt.title(\"Courbe de perte (pré-entraînement -> fine-tune)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0VmJQpNt_mo"
      },
      "source": [
        "#### <u><u><span style=\"color:#1E90FF\">***9. Évaluation du Modèle***</span></u>\n",
        "\n",
        "- ***<span style=\"color:#32CD32\">Objectif :***</span> Phase de test : ROUGE (Recall-Oriented Understudy for Gisting Evaluation) sert d’indicateur principal pour mesurer la qualité du résumé.\n",
        "\n",
        "- ***<span style=\"color:#32CD32\">ROUGE-1 :***</span> Mesure l’alignement entre prédiction et référence via les unités lexicales partagées.\n",
        "\n",
        "- ***<span style=\"color:#32CD32\">ROUGE-2 :***</span> Mesure la cohérence via les bigrammes partagés entre prédiction et référence.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UQbVyrMht_mp"
      },
      "outputs": [],
      "source": [
        "def generer_resume(model, article_text):\n",
        "    model.eval()\n",
        "\n",
        "    # préparation de l’entrée : Article + <SEP>\n",
        "    tokens = clean_text(article_text)\n",
        "    ids = [stoi.get(t, stoi[\"<UNK>\"]) for t in tokens]\n",
        "    ids.append(stoi[\"<SEP>\"])\n",
        "\n",
        "    # si le texte serait vide après nettoyage\n",
        "    if len(ids) == 0:\n",
        "        ids = [stoi[\"<SEP>\"]]\n",
        "\n",
        "    context = torch.tensor(ids, dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    # g\"nération du résumé\n",
        "    generated_ids = []\n",
        "    for _ in range(20):  # on génère maximum 20 tokens\n",
        "        logits, _ = model(context[:, -block_size:])\n",
        "        probs = F.softmax(logits[:, -1, :], dim=-1)\n",
        "        next_idx = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "        # si <EOS> → fin de génération\n",
        "        if next_idx.item() == stoi[\"<EOS>\"]:\n",
        "            break\n",
        "\n",
        "        context = torch.cat((context, next_idx), dim=1)\n",
        "        generated_ids.append(next_idx.item())\n",
        "\n",
        "    # conversion des IDs vers texte\n",
        "    return \" \".join([itos[i] for i in generated_ids])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hBkVIJleyDvM"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "Stemmer and/or `rougeLsum` requires that `nltk` is installed. Use `pip install nltk`.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m rouge = \u001b[43mROUGEScore\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# --- Évaluation ROUGE ---\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Évaluation ROUGE avec TorchMetrics ---\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Dev/Torch/.venv/lib/python3.13/site-packages/torchmetrics/text/rouge.py:118\u001b[39m, in \u001b[36mROUGEScore.__init__\u001b[39m\u001b[34m(self, use_stemmer, normalizer, tokenizer, accumulate, rouge_keys, **kwargs)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_stemmer \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mrougeLsum\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m rouge_keys:\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _NLTK_AVAILABLE:\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[32m    119\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mStemmer and/or `rougeLsum` requires that `nltk` is installed. Use `pip install nltk`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    120\u001b[39m         )\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rouge_keys, \u001b[38;5;28mtuple\u001b[39m):\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: Stemmer and/or `rougeLsum` requires that `nltk` is installed. Use `pip install nltk`."
          ]
        }
      ],
      "source": [
        "rouge = ROUGEScore()\n",
        "\n",
        "# --- Évaluation ROUGE ---\n",
        "print(\"\\n--- Évaluation ROUGE avec TorchMetrics ---\")\n",
        "\n",
        "# Jeu de test : les 5 dernières lignes mises de côté\n",
        "df_test = df_summary.iloc[-5:]\n",
        "\n",
        "preds = []\n",
        "targets = []\n",
        "\n",
        "for _, row in df_test.iterrows():\n",
        "    article = row['text']\n",
        "    reference_summary = row['summary']\n",
        "\n",
        "    generated_summary = generer_resume(model, article)\n",
        "\n",
        "    preds.append(generated_summary)\n",
        "    targets.append(reference_summary)\n",
        "\n",
        "    print(f\"Référence : {reference_summary}\")\n",
        "    print(f\"Généré    : {generated_summary}\\n\")\n",
        "\n",
        "# Calcul des scores ROUGE\n",
        "scores = rouge(preds, targets)\n",
        "\n",
        "print(\"Scores finaux :\")\n",
        "print(f\"ROUGE-1 (Unigrammes) : {scores['rouge1_fmeasure'].item():.4f}\")\n",
        "print(f\"ROUGE-2 (Bigrammes)  : {scores['rouge2_fmeasure'].item():.4f}\")\n",
        "print(f\"ROUGE-L (Longest)    : {scores['rougeL_fmeasure'].item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMFPzmHoreQ8"
      },
      "source": [
        "#### <u><u><span style=\"color:#1E90FF\">***9. Inférence***</span></u>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lo-Vdv5reQ9"
      },
      "outputs": [],
      "source": [
        "def test_single_sentence(sentence):\n",
        "    print(f\"Phrase d'entrée : '{sentence}'\")\n",
        "    summary = generer_resume(model, sentence)\n",
        "    print(f\"Résumé généré   : {summary}\")\n",
        "\n",
        "test_sentence = \"Neural networks are a set of algorithms modeled after the human brain.\"\n",
        "test_single_sentence(test_sentence)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
